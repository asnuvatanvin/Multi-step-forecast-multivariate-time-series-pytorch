{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5052459,"sourceType":"datasetVersion","datasetId":2933516}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-23T13:48:28.122080Z","iopub.execute_input":"2024-02-23T13:48:28.122498Z","iopub.status.idle":"2024-02-23T13:48:28.138514Z","shell.execute_reply.started":"2024-02-23T13:48:28.122468Z","shell.execute_reply":"2024-02-23T13:48:28.137283Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"/kaggle/input/road-occupancy-rate/traffic.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:28.141041Z","iopub.execute_input":"2024-02-23T13:48:28.141843Z","iopub.status.idle":"2024-02-23T13:48:28.148277Z","shell.execute_reply.started":"2024-02-23T13:48:28.141798Z","shell.execute_reply":"2024-02-23T13:48:28.146923Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def create_sequences(df, seq_length, horizon):\n    xs, ys = [], []\n    for i in range(len(df) - seq_length - horizon):\n        x = df.iloc[i:(i+seq_length)]\n        y = df.iloc[(i+seq_length):(i+seq_length+horizon)]\n        xs.append(x)\n        ys.append(y)\n    return np.array(xs), np.array(ys)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:28.150334Z","iopub.execute_input":"2024-02-23T13:48:28.151152Z","iopub.status.idle":"2024-02-23T13:48:28.159466Z","shell.execute_reply.started":"2024-02-23T13:48:28.151112Z","shell.execute_reply":"2024-02-23T13:48:28.158513Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"seq_length = 24\nhorizon = 3\ndf = pd.read_csv(\"/kaggle/input/road-occupancy-rate/traffic.csv\")\nprint(df.shape)\nX, y = create_sequences(df, seq_length, horizon)\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:28.162566Z","iopub.execute_input":"2024-02-23T13:48:28.163716Z","iopub.status.idle":"2024-02-23T13:48:35.176068Z","shell.execute_reply.started":"2024-02-23T13:48:28.163603Z","shell.execute_reply":"2024-02-23T13:48:35.174814Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"(17543, 862)\n(17516, 24, 862) (17516, 3, 862)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Splitting into train-test data\ntrain_size = int(len(y) * 0.7)\nval_size = int((len(y)-train_size) * 0.5)\nX_train, X_val, X_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\ny_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n# Create TensorDataset\nX_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).float()\nX_val = torch.from_numpy(X_val).float()\ny_val = torch.from_numpy(y_val).float()\nX_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).float()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:35.177471Z","iopub.execute_input":"2024-02-23T13:48:35.177829Z","iopub.status.idle":"2024-02-23T13:48:36.087521Z","shell.execute_reply.started":"2024-02-23T13:48:35.177799Z","shell.execute_reply":"2024-02-23T13:48:36.086472Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.089006Z","iopub.execute_input":"2024-02-23T13:48:36.089890Z","iopub.status.idle":"2024-02-23T13:48:36.096917Z","shell.execute_reply.started":"2024-02-23T13:48:36.089840Z","shell.execute_reply":"2024-02-23T13:48:36.095517Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"torch.Size([12261, 24, 862])\ntorch.Size([12261, 3, 862])\ntorch.Size([2628, 24, 862])\ntorch.Size([2628, 3, 862])\ntorch.Size([2627, 24, 862])\ntorch.Size([2627, 3, 862])\n","output_type":"stream"}]},{"cell_type":"code","source":"train = TensorDataset(X_train, y_train)\ntrain_loader = DataLoader(train, batch_size = 32, shuffle = False, drop_last = True)\n\nval = TensorDataset(X_val, y_val)\nval_loader = DataLoader(val, batch_size = 32, shuffle = False, drop_last = True)\n\ntest = TensorDataset(X_test, y_test)\ntest_loader = DataLoader(test, batch_size = 32, shuffle = False, drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.098615Z","iopub.execute_input":"2024-02-23T13:48:36.099498Z","iopub.status.idle":"2024-02-23T13:48:36.223077Z","shell.execute_reply.started":"2024-02-23T13:48:36.099457Z","shell.execute_reply":"2024-02-23T13:48:36.221755Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, input_size,hidden_size,num_layers,output_size):\n        super(LSTM, self).__init__()\n        # Define lstm layer\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        # Initialize long-term memory\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        # Pass all inputs to lstm layer\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.224494Z","iopub.execute_input":"2024-02-23T13:48:36.224941Z","iopub.status.idle":"2024-02-23T13:48:36.234789Z","shell.execute_reply.started":"2024-02-23T13:48:36.224910Z","shell.execute_reply":"2024-02-23T13:48:36.233302Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"input_size = 862  #number of features\nhidden_size = 32 #how many features LSTM should create\nnum_layers = 2 #number of stacked LSTM layers\noutput_size = 862 #number of predicted values\nbatch_size = 32\nmodel = LSTM(input_size,hidden_size,num_layers,output_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.236465Z","iopub.execute_input":"2024-02-23T13:48:36.236810Z","iopub.status.idle":"2024-02-23T13:48:36.248461Z","shell.execute_reply.started":"2024-02-23T13:48:36.236783Z","shell.execute_reply":"2024-02-23T13:48:36.247389Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\nsummary(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.251419Z","iopub.execute_input":"2024-02-23T13:48:36.251852Z","iopub.status.idle":"2024-02-23T13:48:36.263726Z","shell.execute_reply.started":"2024-02-23T13:48:36.251823Z","shell.execute_reply":"2024-02-23T13:48:36.262924Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nLSTM                                     --\n├─LSTM: 1-1                              123,136\n├─Linear: 1-2                            28,446\n=================================================================\nTotal params: 151,582\nTrainable params: 151,582\nNon-trainable params: 0\n================================================================="},"metadata":{}}]},{"cell_type":"code","source":"learning_rate = 0.01 \nnum_epochs = 20\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ntrain_losses = []\ntest_losses = []\nval_losses = []\n\nfor epoch in range(num_epochs):\n    batch_losses = []\n    for x_batch, y_batch in train_loader:\n        x_batch = x_batch.view([batch_size, -1, input_size])\n        y_batch = y_batch\n        outputs = model(x_batch)\n        outputs = outputs.unsqueeze(1).repeat(1,3,1)\n        optimizer.zero_grad()\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        batch_losses.append(loss.item())\n    training_loss = np.mean(batch_losses)\n    train_losses.append(training_loss)\n    \n    \n    with torch.no_grad():\n        batch_val_losses = []\n        for x_val, y_val in val_loader:\n            x_val = x_val.view([batch_size, -1, input_size])\n            y_val = y_val\n            model.eval()\n            yhat = model(x_val)\n            yhat = yhat.unsqueeze(1).repeat(1,3,1)\n            val_loss = criterion(y_val, yhat).item()\n            batch_val_losses.append(val_loss)\n        validation_loss = np.mean(batch_val_losses)\n        val_losses.append(validation_loss)\n    \n    print(f\"[{epoch+1}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:48:36.265120Z","iopub.execute_input":"2024-02-23T13:48:36.265473Z","iopub.status.idle":"2024-02-23T13:50:45.013829Z","shell.execute_reply.started":"2024-02-23T13:48:36.265443Z","shell.execute_reply":"2024-02-23T13:50:45.012537Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[1] Training loss: 0.0012\t Validation loss: 0.0010\n[2] Training loss: 0.0009\t Validation loss: 0.0010\n[3] Training loss: 0.0008\t Validation loss: 0.0010\n[4] Training loss: 0.0008\t Validation loss: 0.0009\n[5] Training loss: 0.0008\t Validation loss: 0.0009\n[6] Training loss: 0.0008\t Validation loss: 0.0009\n[7] Training loss: 0.0008\t Validation loss: 0.0009\n[8] Training loss: 0.0008\t Validation loss: 0.0009\n[9] Training loss: 0.0008\t Validation loss: 0.0009\n[10] Training loss: 0.0008\t Validation loss: 0.0009\n[11] Training loss: 0.0008\t Validation loss: 0.0009\n[12] Training loss: 0.0008\t Validation loss: 0.0009\n[13] Training loss: 0.0008\t Validation loss: 0.0009\n[14] Training loss: 0.0008\t Validation loss: 0.0009\n[15] Training loss: 0.0008\t Validation loss: 0.0009\n[16] Training loss: 0.0008\t Validation loss: 0.0009\n[17] Training loss: 0.0008\t Validation loss: 0.0009\n[18] Training loss: 0.0008\t Validation loss: 0.0009\n[19] Training loss: 0.0008\t Validation loss: 0.0009\n[20] Training loss: 0.0008\t Validation loss: 0.0009\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    test_outputs = model(X_test)\n    test_outputs = test_outputs.unsqueeze(1).repeat(1,3,1)\n    test_loss = criterion(test_outputs, y_test)\n    print(f\"Test Loss: {test_loss.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T13:50:58.009583Z","iopub.execute_input":"2024-02-23T13:50:58.010008Z","iopub.status.idle":"2024-02-23T13:50:58.371870Z","shell.execute_reply.started":"2024-02-23T13:50:58.009975Z","shell.execute_reply":"2024-02-23T13:50:58.370785Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Test Loss: 0.0012\n","output_type":"stream"}]}]}